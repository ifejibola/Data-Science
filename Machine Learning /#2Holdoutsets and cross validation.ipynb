{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "#Choose a model and hyper parameters\n",
    "    #the nearest neighbor model is an instance-based estimator that simply stores\n",
    "        #the training data, and predicts labels by comparing new data to these stored points\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9066666666666666"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Holdout sets,\n",
    "from sklearn.model_selection import train_test_split\n",
    "    #split the data with 50% in each set\n",
    "        #(xtrain, xtest, ytrain, ytest)\n",
    "X1, X2, y1, y2 = train_test_split(X,y, random_state=0, train_size=0.5)\n",
    "\n",
    "#fit the model on one set of data\n",
    "model.fit(X1, y1)\n",
    "\n",
    "#evaluate the model on the second set of data\n",
    "y2_model = model.predict(X2)\n",
    "accuracy_score(y2, y2_model)\n",
    "\n",
    "#One disadvantage of using a holdout set for model validation is that we have lost a poriton \n",
    "#of our data to model training, half the dataset does not  contribute to the training of the model, NOT OPTIMAL!!\n",
    "#especially if the inital set of training data is small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOLUTION: squence of fits - Cross-validation \n",
    "    # Each subset of data is used both as a training set and validation set\n",
    "y2_model = model.fit(X1,y1).predict(X2)\n",
    "y1_model = model.fit(X2, y2).predict(X1)\n",
    "accuracy_score(y1, y1_model), accuracy_score(y2, y2_model) \n",
    "    #Two accuracy scores combined by taking the mean to get a better measure of the global model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 0.96666667, 0.93333333, 0.93333333, 1.        ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Two-fold cross validation \n",
    "#Two accuracy scores combined by taking the mean to get a better measure of the global model performance.\n",
    "    #split the data into five groups, and use each of them to evaluate the model fit on the other 4/5 of the data.\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(model, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
